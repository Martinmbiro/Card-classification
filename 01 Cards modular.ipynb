{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOnvjdU5hVEzWyZrmOX0cV7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martinmbiro/Card-classification/blob/main/01%20Cards%20modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing Modules**\n",
        "> In this notebook, I'll be creating modules for the end to end project on card classification\n",
        "\n",
        "> ðŸ’Ž **Pro Tip**\n",
        "+ Modules help organize code logically, promote code reusability and cleaner code"
      ],
      "metadata": {
        "id": "VNgtMDr3cJzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to delete modules.zip and helper_modules folder\n",
        "# !rm -rf /content/helper_modules/\n",
        "# !rm -rf /content/modules.zip"
      ],
      "metadata": {
        "id": "B9402AX88M5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwRn-1MjGFvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f54edf-da3c-450d-be35-ed3d13524c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "torchvision version: 0.21.0+cu124\n"
          ]
        }
      ],
      "source": [
        "# import torch, torchvision, pathlib\n",
        "import torch, torchvision, pathlib\n",
        "\n",
        "# print versions\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'torchvision version: {torchvision.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ðŸ“ **Note**  \n",
        "+ To **write** a code cell's content into a `*.py`, file we'll use the _magic command_ `%%writefile filename.py`\n",
        "+ To **append** a code cell's content into a `*.py`, file we'll use the _magic command_ `%%writefile -a filename.py`"
      ],
      "metadata": {
        "id": "lvtWRPbmcfSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data\n",
        "> First, we'll create a directory to hold all the custom modules we write\n",
        "+ To create directories, we'll make use of the [`pathlib`](https://docs.python.org/3/library/pathlib.html) python module"
      ],
      "metadata": {
        "id": "kT3euMU9c0Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create directory for helper modules\n",
        "HELPER_MODULES = pathlib.Path('helper_modules')\n",
        "HELPER_MODULES.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "NfEmwYLHRZZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/data_loader.py\n",
        "import kagglehub as kh, zipfile, shutil, os, pathlib, torch, numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms.v2 as T\n",
        "\n",
        "# Dataset Wrapper class\n",
        "class CardsWrapper(Dataset):\n",
        "  def __init__(self, path:pathlib.PosixPath, transform:T.Compose):\n",
        "    self.d_set = ImageFolder(root=path, transform=transform)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.d_set)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img, lb = self.d_set[index]\n",
        "    return img, lb\n",
        "\n",
        "  @property\n",
        "  def idx_to_class(self):\n",
        "    mapper = {idx : cls for cls, idx in self.d_set.class_to_idx.items()}\n",
        "    return mapper\n",
        "\n",
        "  @property\n",
        "  def classes(self):\n",
        "    return self.d_set.classes\n",
        "\n",
        "# define image transforms\n",
        "_card_transforms = T.Compose([\n",
        "    T.PILToTensor(),\n",
        "    T.ToDtype(torch.float32, scale=True),\n",
        "    T.Resize((128,128)),\n",
        "    T.CenterCrop((128, 128))\n",
        "])\n",
        "\n",
        "# download folder\n",
        "_DOWNLOAD_DIR = pathlib.Path('cards')\n",
        "_DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# function to return dataloaders for train, validation, test\n",
        "def get_dataloaders() -> tuple[DataLoader, DataLoader, DataLoader, dict[int, str]]:\n",
        "  \"\"\"\n",
        "    Downloads, extracts, and creates dataloaders for the cards image dataset.\n",
        "\n",
        "    This function downloads the \"cards-image-datasetclassification\" dataset from Kaggle,\n",
        "    archives it, extracts it to a local directory, and then creates PyTorch DataLoader\n",
        "    objects for the training, testing, and validation sets.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple containing the following elements:\n",
        "            - train_dl (DataLoader): DataLoader for the training set.\n",
        "            - test_dl (DataLoader): DataLoader for the testing set.\n",
        "            - val_dl (DataLoader): DataLoader for the validation set.\n",
        "            - idx_to_class (dict[int, str]): A dictionary mapping class indices to class labels.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    FileNotFoundError\n",
        "        If the Kaggle dataset download fails or the zip file cannot be found.\n",
        "    Exception\n",
        "        If any other errors occur during dataset processing.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> train_loader, test_loader, val_loader, class_mapping = get_dataloaders()\n",
        "    >>> print(type(train_loader))\n",
        "    <class 'torch.utils.data.dataloader.DataLoader'>\n",
        "    >>> print(type(class_mapping))\n",
        "    <class 'dict'>\n",
        "  \"\"\"\n",
        "  # Download latest version of dataset from kaggle\n",
        "  _cache = kh.dataset_download(\"gpiosenka/cards-image-datasetclassification\")\n",
        "\n",
        "  # archive the files\n",
        "  shutil.make_archive(base_name=_DOWNLOAD_DIR/'data', format='zip', root_dir=_cache)\n",
        "\n",
        "  # extract the files\n",
        "  with zipfile.ZipFile(_DOWNLOAD_DIR/'data.zip', mode='r') as zipf:\n",
        "    zipf.extractall(path=_DOWNLOAD_DIR)\n",
        "\n",
        "  # create datasets first\n",
        "  train_data = CardsWrapper(path='/content/cards/train', transform=_card_transforms)\n",
        "  test_data = CardsWrapper(path='/content/cards/test', transform=_card_transforms)\n",
        "  val_data = CardsWrapper(path='/content/cards/valid', transform=_card_transforms)\n",
        "\n",
        "  # create dataloaders\n",
        "  train_dl = DataLoader(\n",
        "      dataset=train_data, batch_size=32, shuffle=True, pin_memory=True, num_workers=os.cpu_count())\n",
        "  test_dl = DataLoader(\n",
        "      dataset=test_data, batch_size=32, shuffle=True, pin_memory=True, num_workers=os.cpu_count())\n",
        "  val_dl = DataLoader(\n",
        "      dataset=val_data, batch_size=32, shuffle=True, pin_memory=True, num_workers=os.cpu_count())\n",
        "\n",
        "  # return\n",
        "  return train_dl, test_dl, val_dl, train_data.idx_to_class"
      ],
      "metadata": {
        "id": "cS_-MgXrZOFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ea4763-d0a5-422a-ff2f-8bb050e76a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the [`resnet`](https://research.google/blog/efficientnet-improving-accuracy-and-efficiency-through-automl-and-model-scaling/#:~:text=EfficientNet%2DB0%20is%20the%20baseline,than%20the%20best%20existing%20CNN.) architecture\n",
        "> With the help of the [`timm`](https://huggingface.co/docs/timm/v1.0.15/en/index) library, I'll load the [`resnet14t`](https://huggingface.co/timm/resnet14t.c3_in1k) CNN architecture and alter the `classifier` layer by specifying `53` classes\n",
        "\n",
        "> The function defined here will return a `model`, `Optimizer` and `loss function`\n",
        "+ Also, we'll use [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#adam) as optimizer and [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#crossentropyloss) as loss function, since this is a multi-class classification problem\n"
      ],
      "metadata": {
        "id": "-cevJd4pi3o7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ðŸ”” **Info**\n",
        "+ A standard deck of cards contains `52` cards from _clubs_, _hearts_, _diamonds_ and _spades_ suits, and a _joker_ card\n",
        "+ A quickstart guide to using `timm` is linked [here](https://huggingface.co/docs/timm/v1.0.15/en/quickstart#quickstart)\n",
        "+ For better generalization and to reduce training time, we'll leverage on **Transfer Learning.** Hence, the model we declare here will be **pre-trained** from the start"
      ],
      "metadata": {
        "id": "fdKIa7SykM9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/model_builder.py\n",
        "import timm, torch\n",
        "\n",
        "def get_model(device:str) -> tuple[torch.nn.Module, torch.optim.Optimizer, torch.nn.Module]:\n",
        "  \"\"\"\n",
        "    Creates and initializes a model, optimizer, and loss function for training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    device : str\n",
        "        The device to which the model should be moved. Common values include 'cuda' for GPU or 'cpu' for CPU.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple containing three elements:\n",
        "        - model (torch.nn.Module): The model initialized with the resnet14t architecture for 53 classes.\n",
        "        - opt (torch.optim.Optimizer): The Adam optimizer initialized with the model's parameters.\n",
        "        - loss_fn (torch.nn.Module): The CrossEntropyLoss function used for multi-class classification.\n",
        "    \"\"\"\n",
        "  # pretrained model, with 53 classes for output layer\n",
        "  model = timm.create_model(\n",
        "      model_name='resnet14t',\n",
        "      num_classes=53,\n",
        "      pretrained=True).to(device)\n",
        "\n",
        "  # optimizer\n",
        "  opt = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "  # loss function\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  return model, opt, loss_fn"
      ],
      "metadata": {
        "id": "7Sxd4ONdmElh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e0f1ea-a6b5-43d6-f1d8-fa41fee1d14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early stopping\n",
        "> ðŸ’Ž **Pro Tip**\n",
        "\n",
        "> [Early stopping](https://www.linkedin.com/advice/1/what-benefits-drawbacks-early-stopping#:~:text=Early%20stopping%20is%20a%20form,to%20increase%20or%20stops%20improving.) is a mechanism of stopping training when the validation loss stops improving; with a view to preventing _overfitting_ on the training data\n",
        "+ Here, we'll create a class to take care of _early-stopping_"
      ],
      "metadata": {
        "id": "1O0iefHwwMkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/utils.py\n",
        "import torch, pathlib, numpy as np, matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from torch.utils.data import Dataset, Subset\n",
        "import torch, seaborn as sns, pandas as pd\n",
        "from copy import deepcopy\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torchvision.transforms.v2 as T\n",
        "from pathlib import Path\n",
        "from itertools import chain\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "class EarlyStopping:\n",
        "  \"\"\"\n",
        "  Early stopping to prevent overfitting.\n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "  counter : int\n",
        "      Counter to track the number of epochs without improvement.\n",
        "  patience : int\n",
        "      Number of epochs to wait after the last best score.\n",
        "  min_delta : float\n",
        "      Minimum change in the monitored quantity to qualify as an improvement.\n",
        "  score_type : str\n",
        "      'loss' or 'metric', determines the direction of improvement.\n",
        "  best_epoch : int\n",
        "      Epoch with the best score.\n",
        "  best_score : float\n",
        "      Best score achieved so far.\n",
        "  best_state_dict : dict\n",
        "      State dictionary of the model at the best score.\n",
        "  stop_early : bool\n",
        "      Flag to indicate if early stopping should be triggered.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, score_type: str, min_delta: float = 0.0, patience: int = 5):\n",
        "    \"\"\"\n",
        "    Initializes the EarlyStopping object.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    score_type : str\n",
        "        'loss' or 'metric', determines the direction of improvement.\n",
        "    min_delta : float, optional\n",
        "        Minimum change in the monitored quantity to qualify as an improvement. Defaults to 0.0.\n",
        "    patience : int, optional\n",
        "        Number of epochs to wait after the last best score. Defaults to 5.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    Exception\n",
        "        If score_type is not 'metric' or 'loss'.\n",
        "    \"\"\"\n",
        "    self.counter = 0\n",
        "    self.patience = patience\n",
        "    self.min_delta = min_delta\n",
        "    self.score_type = score_type\n",
        "    self.best_epoch = None\n",
        "    self.best_score = None\n",
        "    self.best_state_dict = None\n",
        "    self.stop_early = False\n",
        "\n",
        "    if (self.score_type != 'metric') and (self.score_type != 'loss'):\n",
        "        err_msg = 'score_type can only be \"metric\" or \"loss\"'\n",
        "        raise Exception(err_msg)\n",
        "\n",
        "  def __call__(self, model: torch.nn.Module, ep: int, ts_score: float):\n",
        "    \"\"\"\n",
        "    Checks if early stopping should be triggered based on the current score.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The model being trained.\n",
        "    ep : int\n",
        "        The current epoch number.\n",
        "    ts_score : float\n",
        "        The current score (loss or metric).\n",
        "    \"\"\"\n",
        "    if self.best_epoch is None:\n",
        "        self.best_epoch = ep\n",
        "        self.best_score = ts_score\n",
        "        self.best_state_dict = deepcopy(model.state_dict())\n",
        "\n",
        "    elif (self.best_score - ts_score >= self.min_delta) and (self.score_type == 'loss'):\n",
        "        self.best_epoch = ep\n",
        "        self.best_score = ts_score\n",
        "        self.best_state_dict = deepcopy(model.state_dict())\n",
        "        self.counter = 0\n",
        "\n",
        "    elif (ts_score - self.best_score >= self.min_delta) and (self.score_type == 'metric'):\n",
        "        self.best_epoch = ep\n",
        "        self.best_score = ts_score\n",
        "        self.best_state_dict = deepcopy(model.state_dict())\n",
        "        self.counter = 0\n",
        "\n",
        "    else:\n",
        "        self.counter += 1\n",
        "        if self.counter >= self.patience:\n",
        "            self.stop_early = True\n"
      ],
      "metadata": {
        "id": "kJfNgLoq8YL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd053ec-bd06-47e8-e03b-24e8fb001248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training / evaluation\n",
        "> Here, I'll define functions for training and testing batches of data, as well as a function to return true labels, `y_true`, prediction labels, `y_pred` and prediction probabilities `y_proba`"
      ],
      "metadata": {
        "id": "JNLF2yZfxo-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/train_test.py\n",
        "import torch, numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# del torch, F, f1_score, accuracy_score\n",
        "\n",
        "# function for model training\n",
        "def train_batches(model: torch.nn.Module, train_dl: torch.utils.data.DataLoader,\n",
        "                  optimizer: torch.optim.Optimizer, loss_fn: torch.nn.Module, device: str) -> tuple[float, float, float]:\n",
        "  \"\"\"\n",
        "  Trains model on all batches of the training set DataLoader and returns\n",
        "  average training loss, accuracy, and F1 score.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      The model being trained.\n",
        "  train_dl : torch.utils.data.DataLoader\n",
        "      DataLoader for training data.\n",
        "  optimizer : torch.optim.Optimizer\n",
        "      The optimizer.\n",
        "  loss_fn : torch.nn.Module\n",
        "      Function used to calculate loss.\n",
        "  device : str\n",
        "      The device on which computation occurs.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  tuple\n",
        "      A tuple containing:\n",
        "          - ls (float): Average training loss across all batches.\n",
        "          - acc (float): Average training accuracy across all batches.\n",
        "          - f1 (float): Average training F1 score across all batches.\n",
        "  \"\"\"\n",
        "  # for reproducibility\n",
        "  torch.manual_seed(0)\n",
        "  torch.cuda.manual_seed(0)\n",
        "  ls, acc, f1 = 0, 0, 0\n",
        "\n",
        "  # training mode\n",
        "  model.train()\n",
        "\n",
        "  for x, y in train_dl:\n",
        "      # move x, y to device\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      # zero_grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward pass\n",
        "      logits = model(x)\n",
        "      y_pred = F.softmax(logits, dim=1).argmax(dim=1).cpu().numpy()\n",
        "\n",
        "      # loss\n",
        "      loss = loss_fn(logits, y)\n",
        "      # accumulate values\n",
        "      ls += loss.item()\n",
        "      acc += accuracy_score(y_true=y.cpu().numpy(), y_pred=y_pred)\n",
        "      f1 += f1_score(y_true=y.cpu().numpy(),\n",
        "                     y_pred=y_pred,\n",
        "                     average='macro')\n",
        "\n",
        "      # back propagation\n",
        "      loss.backward()\n",
        "      # optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "  # compute averages\n",
        "  ls /= len(train_dl)\n",
        "  acc /= len(train_dl)\n",
        "  f1 /= len(train_dl)\n",
        "\n",
        "  # return values\n",
        "  return ls, acc, f1\n",
        "\n",
        "def test_batches(model: torch.nn.Module, val_dl: torch.utils.data.DataLoader,\n",
        "                 loss_fn: torch.nn.Module, device: str) -> tuple[float, float, float]:\n",
        "  \"\"\"\n",
        "  Evaluates model on all batches of the test set DataLoader and returns\n",
        "  average test loss, accuracy, and F1 score.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      The model being evaluated.\n",
        "  test_dl : torch.utils.data.DataLoader\n",
        "      DataLoader for test data.\n",
        "  loss_fn : torch.nn.Module\n",
        "      Function used to calculate loss.\n",
        "  device : str\n",
        "      The device on which computation occurs.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  tuple\n",
        "      A tuple containing:\n",
        "          - ls (float): Average test loss across all batches.\n",
        "          - acc (float): Average test accuracy across all batches.\n",
        "          - f1 (float): Average test F1 score across all batches.\n",
        "  \"\"\"\n",
        "  ls, f1, acc = 0, 0, 0\n",
        "\n",
        "  # evaluation-mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for x, y in val_dl:\n",
        "        # move x, y to device\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        logits = model(x)\n",
        "        y_pred = F.softmax(logits, dim=1).argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # loss\n",
        "        loss = loss_fn(logits, y)\n",
        "\n",
        "        # accumulate values\n",
        "        ls += loss.item()\n",
        "        acc += accuracy_score(y_true=y.cpu().numpy(), y_pred=y_pred)\n",
        "        f1 += f1_score(y_true=y.cpu().numpy(),\n",
        "                       y_pred=y_pred,\n",
        "                       average='macro')\n",
        "\n",
        "  # compute averages\n",
        "  ls /= len(val_dl)\n",
        "  acc /= len(val_dl)\n",
        "  f1 /= len(val_dl)\n",
        "\n",
        "  # return values\n",
        "  return ls, acc, f1\n",
        "\n",
        "\n",
        "def true_preds_proba(model: torch.nn.Module, test_dl: torch.utils.data.DataLoader,\n",
        "                     device: str) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"\n",
        "  A function that returns true labels, predictions, and prediction probabilities\n",
        "  from the passed DataLoader.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      A neural network that subclasses torch.nn.Module.\n",
        "  test_dl : torch.utils.data.DataLoader\n",
        "      A DataLoader for the test dataset.\n",
        "  device : str\n",
        "      The device on which computation occurs.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  tuple\n",
        "      A tuple containing:\n",
        "          - y_true (np.ndarray): A numpy array with true labels.\n",
        "          - y_pred (np.ndarray): A numpy array with predicted labels.\n",
        "          - y_proba (np.ndarray): A numpy array with predicted probabilities.\n",
        "  \"\"\"\n",
        "  # empty lists\n",
        "  y_true, y_preds, y_proba = list(), list(), list()\n",
        "  with torch.inference_mode():\n",
        "      model.eval()  # set eval mode\n",
        "      for x, y in test_dl:\n",
        "          # move x to device\n",
        "          x = x.to(device)\n",
        "\n",
        "          # make prediction\n",
        "          logits = model(x)\n",
        "\n",
        "          # prediction and probabilities\n",
        "          proba = F.softmax(logits, dim=1)\n",
        "          pred = F.softmax(logits, dim=1).argmax(dim=1)\n",
        "\n",
        "          # append\n",
        "          y_preds.append(pred)\n",
        "          y_proba.append(proba)\n",
        "          y_true.append(y)\n",
        "\n",
        "  y_preds = torch.concatenate(y_preds).cpu().numpy()\n",
        "  y_proba = torch.concatenate(y_proba).cpu().numpy()\n",
        "  y_true = torch.concatenate(y_true).numpy()\n",
        "\n",
        "  return y_true, y_preds, y_proba\n"
      ],
      "metadata": {
        "id": "ixNnOWrKxrci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9695dd-3ea6-4d03-da3a-3fb16c234724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/train_test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot results\n",
        "> Here, I'll define helper functions for plotting training metrics"
      ],
      "metadata": {
        "id": "GE2tc9RUahxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to plot train and test results\n",
        "def plot_train_results(ep_list: list, train_score: list, test_score: list,\n",
        "                       ylabel: str, title: str, best_epoch: int):\n",
        "  \"\"\"\n",
        "  Plots training and test results against each other.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  ep_list : list\n",
        "      A list containing all epochs used in the optimization loop.\n",
        "  train_score : list\n",
        "      A list containing the training scores from the optimization loop.\n",
        "  test_score : list\n",
        "      A list containing the test scores from the optimization loop.\n",
        "  ylabel : str\n",
        "      Label for the y-axis of the plot.\n",
        "  title : str\n",
        "      Title for the plot.\n",
        "  best_epoch : int\n",
        "      Best epoch for which early stopping occurred.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  f, ax = plt.subplots(figsize=(5, 3), layout='constrained')\n",
        "\n",
        "  # train loss\n",
        "  ax.plot(ep_list, train_score, label='Training',\n",
        "          linewidth=1.7, color='#0047ab')\n",
        "\n",
        "  # test loss\n",
        "  ax.plot(ep_list, test_score, label='Validation',\n",
        "          linewidth=1.7, color='#990000')\n",
        "  # vertical line (for early stopping)\n",
        "  if best_epoch is not None:\n",
        "      ax.axvline(best_epoch, linestyle='--', color='#000000', linewidth=1.0,\n",
        "                  label=f'Best ep ({best_epoch})')\n",
        "\n",
        "  # axis, title\n",
        "  ax.set_title(title, weight='black')\n",
        "  ax.set_ylabel(ylabel)\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.tick_params(axis='both', labelsize=9)\n",
        "  plt.grid(color='#e5e4e2')\n",
        "\n",
        "  # legend\n",
        "  f.legend(fontsize=9, loc='upper right',\n",
        "            bbox_to_anchor=(1.28, 0.93),\n",
        "            fancybox=False)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray):\n",
        "  \"\"\"\n",
        "  Plots a confusion matrix for all classes.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  y_true : np.ndarray\n",
        "      An ndarray containing the true label values.\n",
        "  y_pred : np.ndarray\n",
        "      An ndarray containing the predicted label values.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  # define figure and plot\n",
        "  _, ax = plt.subplots(figsize=(8.0,8.0), layout='compressed')\n",
        "  # plot\n",
        "  ConfusionMatrixDisplay.from_predictions(\n",
        "      y_true=y_true,\n",
        "      y_pred=y_pred, cmap='Blues', colorbar=False, ax=ax)\n",
        "\n",
        "  # set x and y labels\n",
        "  ax.set_ylabel('True Labels', weight='black')\n",
        "  ax.set_xlabel('Predicted Labels', weight='black',\n",
        "                color='#dc143c')\n",
        "  # set tick size and position\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.xaxis.set_label_position('top')\n",
        "  ax.tick_params(axis='both', labelsize=7)\n",
        "\n",
        "  # change annotation font\n",
        "  for txt in ax.texts:\n",
        "      txt.set_fontsize(7.5)\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "UpswMomY6dB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff0b4d9-1e8d-481f-c5df-4a46399a9ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model\n",
        "> ðŸ”” **Info**\n",
        "\n",
        "> Pytorch's recommended way of saving a model is by saving its [`state_dict`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict). To do this, the [documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-state-dict-recommended) recommends calling [`torch.save(obj=model.state_dict(), f=PATH)`](https://pytorch.org/docs/stable/generated/torch.save.html#torch-save)\n",
        "+ `f` - a file-like object or a string or `os.PathLike` object containing a file name. To work with paths, we'll use Python's [`pathlib`](https://docs.python.org/3/library/pathlib.html) module\n",
        "+ A common PyTorch convention is to save models using either a `.pt` or `.pth` file extension\n",
        "+ Also, it's good practice to move the model to the `cpu` before saving its `state_dict`"
      ],
      "metadata": {
        "id": "q8dmvDKZjJco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to save model to specified directory\n",
        "def save_model(model: torch.nn.Module, path: pathlib.PosixPath):\n",
        "    \"\"\"\n",
        "    Saves the model's state_dict to a specified path.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The model to save.\n",
        "    path : pathlib.PosixPath\n",
        "        The path where the model's state_dict will be saved.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    torch.save(obj=model.cpu().state_dict(), f=path)\n",
        "    print(f\"MODEL'S state_dict SAVED TO: {path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvslsO4nTJL",
        "outputId": "712d9c9c-e9a0-405e-9e67-8eb2b7900c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load saved model\n",
        "> To load a previously saved model's `state_dict`, we call\n",
        " [`torch.load(f=PATH, weights_only=True)`](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load) that loads an object saved using [`torch.save()`](https://pytorch.org/docs/stable/generated/torch.save.html#torch-save) from a file:\n",
        "\n",
        "```\n",
        "    model = TheModelClass(*args, **kwargs)\n",
        "    model.load_state_dict(torch.load(PATH, weights_only=True))\n",
        "    model.eval()\n",
        "```\n",
        "\n",
        "> ðŸ”” **Info**\n",
        "+ Remember that you must call `model.eval()` before running inference\n",
        "+ `f` - a file-like object or a string or `os.PathLike` object containing a file name. To work with paths, we'll use Python's [`pathlib`](https://docs.python.org/3/library/pathlib.html) module\n",
        "+ Note that a `model` class must have been defined earlier, before calling [`model.load_state_dict()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict) on the object"
      ],
      "metadata": {
        "id": "5f5k3J5rcAlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to load model from a specified path\n",
        "def load_model(model: torch.nn.Module, path: pathlib.PosixPath):\n",
        "  \"\"\"\n",
        "  Loads the model's state_dict from a specified path.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      A new object of the model class.\n",
        "  path : pathlib.PosixPath\n",
        "      Path pointing to a previously saved model's state_dict.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  model : torch.nn.Module\n",
        "      The model returned after loading the state_dict.\n",
        "  \"\"\"\n",
        "  # overwrite state_dict\n",
        "  model.load_state_dict(torch.load(f=path, weights_only=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLlas76CcGLJ",
        "outputId": "adf9b0c6-fadc-4939-b3e8-39b90f2829e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make inference\n",
        "> Here, I'll declare functions to make inference on `test` data\n",
        "+ On a single random image\n",
        "+ On multiple `(12)` random images"
      ],
      "metadata": {
        "id": "qiK8QJ57hASq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "# function to make inference on a single random image from testset\n",
        "def make_single_inference(model: torch.nn.Module, dataset: torch.utils.data.Dataset,\n",
        "                          label_map: dict, device: str):\n",
        "  \"\"\"\n",
        "  Makes inference using a random data point from the test dataset.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      A model (subclassing torch.nn.Module) to make inference.\n",
        "  dataset : torch.utils.data.Dataset\n",
        "      The Dataset to use for testing purposes.\n",
        "  label_map : dict\n",
        "      A dictionary mapping indices to labels (e.g., {0: 'O', 1: 'X'}).\n",
        "  device : str\n",
        "      Device on which to perform computation.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  # get random image from test_set\n",
        "  idx = np.random.choice(len(dataset))\n",
        "  img, lb = dataset[idx]\n",
        "\n",
        "  # make prediction\n",
        "  with torch.inference_mode():\n",
        "    model.to(device)  # move model to device\n",
        "    model.eval()  # set eval mode\n",
        "    lgts = model.to(device)(img.unsqueeze(0).to(device))\n",
        "    pred = F.softmax(lgts, dim=1).argmax(dim=1)\n",
        "\n",
        "  # print actual retrieved image\n",
        "  plt.figure(figsize=(3.0, 3.0))\n",
        "  # title with label\n",
        "  if pred == lb:\n",
        "    plt.title(\n",
        "        f'Actual: {label_map[lb].title()}\\nPred: {label_map[pred.item()].title()}',\n",
        "        fontsize=8)\n",
        "  else:  # if labels do not match, title = with red color\n",
        "    plt.title(\n",
        "        f'Actual: {label_map[lb].title()}\\nPred: {label_map[pred.item()].title()}',\n",
        "        fontsize=8, color='#de3163', weight='black')\n",
        "  plt.axis(False)\n",
        "  plt.imshow(img.permute(1,2,0))\n",
        "  plt.show()\n",
        "\n",
        "# function to make inference on 12 random images from testset\n",
        "def make_multiple_inference(model: torch.nn.Module, dataset: torch.utils.data.Dataset,\n",
        "                          label_map: dict, device: str):\n",
        "  \"\"\"\n",
        "  Makes inference on multiple random images from the test dataset.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      A model (subclassing torch.nn.Module) to make inference.\n",
        "  dataset : torch.utils.data.Dataset\n",
        "      The Dataset used for evaluation purposes.\n",
        "  label_map : dict\n",
        "      A dictionary mapping indices to labels (e.g., {0: 'O', 1: 'X'}).\n",
        "  device : str\n",
        "      Device on which to perform computation.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  # get array of 12 random indices of images in test_dataset\n",
        "  indices = np.random.choice(len(dataset), size=12, replace=False)\n",
        "  # create subset from the 12 indices\n",
        "  sub_set = Subset(dataset=dataset, indices=indices)\n",
        "\n",
        "  # define a figure and subplots\n",
        "  f, axs = plt.subplots(2, 6, figsize=(10, 8.5), layout='compressed')\n",
        "\n",
        "  # move model to device & set eval mode\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  # loop through each subplot\n",
        "  for i, ax in enumerate(axs.flat):\n",
        "    img, lb = sub_set[i]  # return image and label\n",
        "\n",
        "    # make inference on image returned\n",
        "    with torch.inference_mode():\n",
        "        lg = model(img.unsqueeze(0).to(device))\n",
        "        pred = F.softmax(lg, dim=1).argmax(dim=1)\n",
        "\n",
        "    ax.imshow(img.permute(1,2,0))\n",
        "    ax.axis(False)\n",
        "    if pred == lb:\n",
        "        ax.set_title(\n",
        "            f'Actual: {label_map[lb].title()}\\nPred: {label_map[pred.item()].title()}',\n",
        "            fontsize=7.5)\n",
        "    else:  # if labels do not match, title = with red color\n",
        "        ax.set_title(\n",
        "            f'Actual: {label_map[lb].title()}\\nPred: {label_map[pred.item()].title()}',\n",
        "            fontsize=7.5, color='#de3163', weight='black')\n",
        "\n",
        "  f.suptitle('Inference Made on 12 Random Test Images',\n",
        "            # y=0.9,\n",
        "            weight='black')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ0t1UlRhDHP",
        "outputId": "fbcc05b9-4e25-4f6b-c623-ac8ca8cd06d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on custom images\n",
        "> Here, I'll write the logic to make inference on custom image, where a user can upload an image of a playing card, and get prediction as well as top5 prediction probabilities"
      ],
      "metadata": {
        "id": "Ny_qK4U-lZqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> First let's define image transforms for image used to run inference, and image plotted with the result"
      ],
      "metadata": {
        "id": "mDcup_nKmQQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# image transforms for inference\n",
        "_img_transform = T.Compose(transforms=[\n",
        "    T.PILToTensor(),\n",
        "    T.ToDtype(dtype=torch.float32, scale=True),\n",
        "    T.Resize((128,128)),\n",
        "    T.CenterCrop((128, 128))\n",
        "])\n",
        "\n",
        "# image transform for plotting\n",
        "_plot_transform = T.Compose([\n",
        "    T.PILToTensor(),\n",
        "    T.Resize((256, 256)),\n",
        "    T.ToDtype(dtype=torch.float32, scale=True)\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVdGxpT-lx6D",
        "outputId": "1179f6d0-8b7b-4309-d65e-2bc5267e562a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Uploading the image\n",
        "> Here, we run the following steps:\n",
        "+ Create an `uploads` folder if it doesn't exist already\n",
        "+ Upload an image using [`google.colab.file.upload()`](https://colab.research.google.com/notebooks/io.ipynb), and check if only ONE image is uploaded\n",
        "+ Here, we use [`itertools.chain()`](https://docs.python.org/3/library/itertools.html#itertools.chain) function to combine multiple iterables gotten from [`pathlib.Path.glob()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob) into a single iterator\n",
        "+ Get the image path\n",
        "+ Turn image into a [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor)"
      ],
      "metadata": {
        "id": "vdKIIR4umcN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ðŸ“ **Note**\n",
        "+ All path related functionality is implemeted using the `pathlib` module"
      ],
      "metadata": {
        "id": "-QpfKb5VoOq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to upload an image for custom inference\n",
        "def _upload_image() -> tuple[torch.Tensor, torch.Tensor]:\n",
        "  \"\"\"\n",
        "    Handles image upload, validation, transformation, and cleanup.\n",
        "\n",
        "    This function performs the following steps:\n",
        "        - Ensures an upload directory exists.\n",
        "        - Prompts the user to upload a single image file.\n",
        "        - Validates that only one file is uploaded.\n",
        "        - Applies image transformations for inference and plotting.\n",
        "        - Deletes all uploaded images after processing.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple of torch.Tensor\n",
        "        A tuple containing:\n",
        "        - `inf_img`: The transformed image tensor used for inference.\n",
        "        - `plot_img`: The transformed image tensor used for plotting or visualization.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    Exception\n",
        "        If more than one file is uploaded\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    Supported image formats include: .png, .jpg, .jpeg, and .gif.\n",
        "    This function is intended to be used in a Colab notebook environment using `google.colab.files.upload`.\n",
        "  \"\"\"\n",
        "  # create folder to upload, if not already there\n",
        "  UPLOAD_DIR = Path('uploads')\n",
        "  UPLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # upload the file to the directory above\n",
        "  upd = files.upload(target_dir=UPLOAD_DIR)\n",
        "\n",
        "  # get all uploaded images\n",
        "  iter_gen = chain(UPLOAD_DIR.glob('*.png'),\n",
        "                    UPLOAD_DIR.glob('*.jpg'),\n",
        "                    UPLOAD_DIR.glob('*.jpeg'),\n",
        "                    UPLOAD_DIR.glob('*.gif'))\n",
        "\n",
        "  if len(upd) != 1:\n",
        "    # delete all uploaded images\n",
        "    for img in iter_gen:\n",
        "      img.unlink(missing_ok=True)\n",
        "    # raise Exception\n",
        "    raise Exception(f'Expected ONE image, but got {len(upd)}.\\nRE-RUN the cell and upload a single image.')\n",
        "\n",
        "  else:\n",
        "    # get image path\n",
        "    img_path = Path(next(iter(upd)))\n",
        "\n",
        "    # turn image into tensor for inference\n",
        "    inf_img = _img_transform(Image.open(img_path))\n",
        "    # for plotting\n",
        "    plot_img = _plot_transform(Image.open(img_path))\n",
        "\n",
        "    # delete all uploads\n",
        "    for img in iter_gen:\n",
        "      img.unlink(missing_ok=True)\n",
        "\n",
        "    return inf_img, plot_img\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNMZxPMjnAP_",
        "outputId": "d1b044e0-31f1-454d-cd8d-83d598c46a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make prediction & plot\n",
        "> Here, using the image tensor resulting from the step above, we make an inference, deriving the label and class probabilities\n",
        "+ Also, we create a [`DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) of the top5 prediction probabilities and their corresponding class labels\n",
        "+ For control over subplot placement in the final plot, we use [`matplotlib.gridspec.GridSpec`](https://matplotlib.org/stable/api/_as_gen/matplotlib.gridspec.GridSpec.html)\n",
        "+ [`seaborn`](https://seaborn.pydata.org/index.html) is also used to make the [`barplot`](https://seaborn.pydata.org/generated/seaborn.barplot.html#seaborn-barplot)"
      ],
      "metadata": {
        "id": "DWskjSheppWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to perform infernce on a single image and display results\n",
        "def custom_inference(model:torch.nn.Module, device:str, label_mapper:dict):\n",
        "  \"\"\"\n",
        "    Performs inference on a single uploaded image, displays the prediction, and visualizes the top-5 class probabilities.\n",
        "\n",
        "    This function:\n",
        "        * Uploads a single image and applies necessary transformations.\n",
        "        * Runs inference using the provided model and device.\n",
        "        * Computes class probabilities using softmax.\n",
        "        * Displays the top predicted label and its probability.\n",
        "        * Creates and displays a bar plot of the top-5 predicted classes with their probabilities.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        A trained PyTorch model for image classification.\n",
        "\n",
        "    device : str\n",
        "        The device to perform inference on (e.g., 'cpu' or 'cuda').\n",
        "\n",
        "    label_mapper : dict\n",
        "        A dictionary mapping class indices (int) to human-readable class labels (str).\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    Exception\n",
        "        If more than one image is uploaded\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - The image must be uploaded using an interactive Colab file upload widget.\n",
        "    - The `_upload_image()` helper is responsible for transformation and validation.\n",
        "    - Torch is used in inference mode to avoid tracking gradients.\n",
        "    - This function assumes the model outputs raw logits for classification.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> label_map = {0: 'cat', 1: 'dog', 2: 'car'}\n",
        "    >>> custom_inference(trained_model, device='cuda', label_mapper=label_map)\n",
        "  \"\"\"\n",
        "  # get tensors from uploaded image\n",
        "  inf_img, plot_img = _upload_image()\n",
        "\n",
        "  #_____MAKE INFERENCE_____\n",
        "  with torch.inference_mode():\n",
        "    model.eval() # eval mode\n",
        "    model.to(device)\n",
        "    # make prediction\n",
        "    logits = model(inf_img.unsqueeze(0).to(device))\n",
        "    # scale logits on 0 -> scale\n",
        "    logits = F.softmax(logits, dim=1)\n",
        "\n",
        "    # label & class probability\n",
        "    y_pred = logits.argmax(dim=1).item()\n",
        "    class_prob = logits.max().item()\n",
        "\n",
        "    #_____PROBABILITY THRESHOLD (Out Of Distribution Detection)_____\n",
        "    if class_prob < 0.50:\n",
        "      err_msg = 'The image uploaded is most likely NOT of a clear / valid PLAYING CARD\\n\\nRE-RUN THE CODE CELL AND UPLOAD A VALID PLAYING CARD IMAGE'\n",
        "      raise Exception(err_msg)\n",
        "\n",
        "    # get top5 indices & values from logits\n",
        "    top5 = logits.topk(5)\n",
        "\n",
        "  #_____MAKE DATAFRAME_____\n",
        "  # make a dataframe out of the top5 predictions & probabilities\n",
        "  df = pd.DataFrame({\n",
        "      'Classes': [label_mapper[c.item()].title() for c in top5.indices.squeeze()],\n",
        "      'Probabilities': top5.values.squeeze().cpu().numpy()\n",
        "  })\n",
        "  # sort dataframe in decsending order\n",
        "  df.sort_values(by='Probabilities', ascending=False, inplace=True)\n",
        "\n",
        "  #_____PLOT_____\n",
        "  # set up figure, gridspec, axes\n",
        "  f = plt.figure(figsize=(9, 3), layout='compressed')\n",
        "  gs = GridSpec(figure=f, nrows=1, ncols=2, width_ratios=[1,3], wspace=0.05)\n",
        "  ax1 = f.add_subplot(gs[0])\n",
        "  ax2 = f.add_subplot(gs[1])\n",
        "\n",
        "  # plot the card\n",
        "  ax1.set_title(f'Predicted: {label_mapper[y_pred].title()}\\nProbability: {class_prob:.2f}',\n",
        "            fontsize=8.5, weight='black', color='#de3163')\n",
        "  ax1.axis(False)\n",
        "  ax1.imshow(plot_img.permute(1,2,0).clamp(min=0, max=1.0))\n",
        "\n",
        "  # bar plot\n",
        "  ax2.set_title('Top 5 Prediction Probabilities', weight='black', fontsize=10,\n",
        "                color='#1f305e')\n",
        "  ax2.set_ylabel('Classes', weight='black', fontsize=8.5)\n",
        "  ax2.set_xlabel('Probabilities', weight='black', fontsize=8.5)\n",
        "  ax2.tick_params(axis='both', labelsize=8)\n",
        "  ax2.grid(axis='x', color='#dbd7d2')\n",
        "  sns.barplot(\n",
        "      data=df,\n",
        "      x='Probabilities', y='Classes', hue='Classes', orient='h', palette='crest',\n",
        "      legend=False, width=0.8, ax=ax2)\n",
        "  # display\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E85ZazEeprwO",
        "outputId": "0b54d818-bd6d-48ee-cc40-9c9f110552a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Archive modules\n",
        "> Here, we'll create a function to archive all the modules `*.py` files into a `*.zip` file with the help of [`make_archive`](https://docs.python.org/3/library/shutil.html#shutil.make_archive) function from the [`shutil`](https://docs.python.org/3/library/shutil.html#module-shutil) python module\n",
        "\n",
        "> âœ‹ **Info**\n",
        "+ The `zip` file containing the helper modules will be then uploaded to the GitHub repository [here](https://github.com/Martinmbiro/Card-classification/tree/main/helper%20modules). That way, the modules can be downloaded and extracted dynamically in code"
      ],
      "metadata": {
        "id": "KyrG_C_hni52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, pathlib\n",
        "\n",
        "def archive_modules(path_to_files: pathlib.PosixPath, zip_name: str):\n",
        "    \"\"\"\n",
        "    Archive a directory into a ZIP file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_to_files : pathlib.PosixPath\n",
        "        The path to the directory or files to be archived.\n",
        "\n",
        "    zip_name : str\n",
        "        The name of the resulting ZIP file (without the extension).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        This function does not return any value. It creates a ZIP archive at the specified location.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This function uses `shutil.make_archive` to create the archive. The archive will be created\n",
        "    in the current working directory unless a full path is provided in the `zip_name`.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> archive_modules(pathlib.Path('/path/to/files'), 'my_archive')\n",
        "    This will create a ZIP archive named 'my_archive.zip' containing the files from the specified directory.\n",
        "\n",
        "    \"\"\"\n",
        "    shutil.make_archive(\n",
        "        base_name=zip_name, format='zip', root_dir=path_to_files)"
      ],
      "metadata": {
        "id": "xjfGfN7BZ9CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# archive modules\n",
        "archive_modules(HELPER_MODULES, 'modules')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGGwUg_ebUDI",
        "outputId": "b0add6fb-87b1-4197-b08e-c2db0e600c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 828 Âµs, sys: 1.97 ms, total: 2.79 ms\n",
            "Wall time: 4.26 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> â–¶ï¸ **Up Next**\n",
        "+ Having created modules out of the most reusable code, I'll implement an end to tend project for classifying playing card images in the subsequent notebook, `02 Cards end to end.ipynb`"
      ],
      "metadata": {
        "id": "huE7PJuzGBva"
      }
    }
  ]
}